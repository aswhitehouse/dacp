#!/usr/bin/env python3
"""
DACP Security Workflow Demo

This demonstrates a real-world security use case with DACP workflow orchestration:
- Threat Analyzer Agent: Analyzes security events for potential threats
- Risk Assessor Agent: Evaluates threats and provides risk scores + recommendations
- Agent-to-Agent Communication: Shows data flow between specialized security agents

This example showcases how DACP can orchestrate multi-agent security analysis
pipelines, demonstrating practical agent communication patterns.
"""

import time
import json
import os
import sys
import importlib.util

# Import DACP for workflow orchestration
import dacp


def print_section(title: str, content: str = None):
    """Print a formatted section header."""
    print(f"\n{'='*70}")
    print(f"ğŸ›¡ï¸  {title}")
    print('='*70)
    if content:
        print(content)


def create_security_incident_test_data():
    """Create realistic security incident test data."""
    return {
        "event_type": "multiple_failed_logins",
        "event_details": "User account 'admin' had 15 failed login attempts from IP 192.168.1.100 within 5 minutes. Account is now locked.",
        "source_ip": "192.168.1.100", 
        "timestamp": "2024-01-15T14:30:00Z",
        "asset_context": "Critical customer database server with PII data"
    }


def load_agent_from_file(file_path: str, class_name: str):
    """Dynamically load an agent class from a file."""
    spec = importlib.util.spec_from_file_location("agent_module", file_path)
    agent_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(agent_module)
    return getattr(agent_module, class_name)


def main():
    """Demonstrate DACP security workflow with agent-to-agent communication."""
    print_section("DACP SECURITY WORKFLOW DEMONSTRATION", 
                  "Two-stage security analysis: Threat Detection â†’ Risk Assessment")
    
    # Create orchestrator for workflow management
    orchestrator = dacp.Orchestrator(session_id=f"security_demo_{int(time.time())}")
    
    print_section("AGENT INITIALIZATION")
    print("ğŸ“‹ This demo requires OAS-generated security agents.")
    print("ğŸ“‹ To run this demo:")
    print("   1. Generate threat-analyzer and risk-assessor agents using OAS")
    print("   2. Place them in the examples/ directory")
    print("   3. Configure API keys in .env files")
    print("")
    print("ğŸ”§ Agent Specifications Available:")
    print("   - threat-analyzer.yaml: Security event analysis agent")
    print("   - risk-assessor.yaml: Risk evaluation and recommendation agent")
    
    # Check if agent files exist (they would be copied here in a real implementation)
    threat_analyzer_path = "examples/threat-analyzer/agent.py"
    risk_assessor_path = "examples/risk-assessor/agent.py"
    
    if not (os.path.exists(threat_analyzer_path) and os.path.exists(risk_assessor_path)):
        print_section("DEMO SIMULATION")
        print("âš ï¸  Agent files not found - running simulation mode")
        
        # Simulate the workflow results
        print_section("SIMULATED SECURITY INCIDENT DATA")
        test_incident = create_security_incident_test_data()
        print(f"ğŸ“Š Event Type: {test_incident['event_type']}")
        print(f"ğŸ“Š Source IP: {test_incident['source_ip']}")
        print(f"ğŸ“Š Timestamp: {test_incident['timestamp']}")
        print(f"ğŸ“Š Details: {test_incident['event_details']}")
        print(f"ğŸ“Š Asset Context: {test_incident['asset_context']}")
        
        print_section("SIMULATED STAGE 1: THREAT ANALYSIS")
        print("ğŸ” [SIMULATED] Threat Analyzer processing security event...")
        simulated_threat_result = {
            "threat_identified": True,
            "threat_type": "brute_force",
            "threat_severity": "high",
            "threat_indicators": ["Multiple failed login attempts", "Admin account targeted", "Short time window"],
            "analysis_summary": "Brute force attack detected against admin account from single IP address"
        }
        
        time.sleep(1)  # Simulate processing time
        print("âœ… [SIMULATED] Threat analysis completed!")
        print(f"   ğŸš¨ Threat Identified: {simulated_threat_result['threat_identified']}")
        print(f"   ğŸ·ï¸  Threat Type: {simulated_threat_result['threat_type']}")
        print(f"   âš ï¸  Severity: {simulated_threat_result['threat_severity']}")
        print(f"   ğŸ“‹ Indicators: {', '.join(simulated_threat_result['threat_indicators'])}")
        print(f"   ğŸ“ Summary: {simulated_threat_result['analysis_summary']}")
        
        print_section("SIMULATED STAGE 2: RISK ASSESSMENT")
        print("âš–ï¸  [SIMULATED] Risk Assessor evaluating threat...")
        simulated_risk_result = {
            "risk_score": 8.5,
            "risk_level": "high",
            "business_impact": "Potential unauthorized access to critical customer database with PII data",
            "immediate_actions": [
                "Immediately block source IP 192.168.1.100",
                "Reset admin account password",
                "Enable enhanced monitoring for admin accounts",
                "Review recent admin account activity"
            ],
            "mitigation_recommendations": [
                "Implement multi-factor authentication for admin accounts",
                "Deploy account lockout policies with progressive delays",
                "Set up real-time alerting for multiple failed logins",
                "Conduct security awareness training for admin users"
            ],
            "escalation_required": True,
            "confidence_level": 0.92
        }
        
        time.sleep(1)  # Simulate processing time
        print("âœ… [SIMULATED] Risk assessment completed!")
        print(f"   ğŸ“Š Risk Score: {simulated_risk_result['risk_score']}/10")
        print(f"   ğŸ·ï¸  Risk Level: {simulated_risk_result['risk_level'].upper()}")
        print(f"   ğŸ’¼ Business Impact: {simulated_risk_result['business_impact']}")
        print(f"   ğŸš¨ Escalation Required: {simulated_risk_result['escalation_required']}")
        print(f"   ğŸ“ˆ Confidence Level: {simulated_risk_result['confidence_level']:.2f}")
        
        print(f"\n   âš¡ Immediate Actions:")
        for i, action in enumerate(simulated_risk_result['immediate_actions'], 1):
            print(f"      {i}. {action}")
        
        print(f"\n   ğŸ›¡ï¸  Mitigation Recommendations:")
        for i, recommendation in enumerate(simulated_risk_result['mitigation_recommendations'], 1):
            print(f"      {i}. {recommendation}")
        
        print_section("WORKFLOW SUMMARY")
        print("ğŸ”„ DACP Agent-to-Agent Communication Flow:")
        print("   1. Threat Analyzer â†’ Analyzed security event")
        print("   2. DACP Runtime â†’ Routed threat analysis to Risk Assessor")
        print("   3. Risk Assessor â†’ Generated comprehensive risk assessment")
        print("   4. DACP Orchestrator â†’ Coordinated data flow between agents")
        
        print(f"\nğŸ“‹ Final Security Assessment:")
        print(f"   â€¢ Threat: {simulated_threat_result['threat_type']} ({simulated_threat_result['threat_severity']})")
        print(f"   â€¢ Risk: {simulated_risk_result['risk_score']}/10 ({simulated_risk_result['risk_level'].upper()})")
        print(f"   â€¢ Escalation: {'YES' if simulated_risk_result['escalation_required'] else 'NO'}")
        print(f"   â€¢ Actions: {len(simulated_risk_result['immediate_actions'])} immediate, {len(simulated_risk_result['mitigation_recommendations'])} mitigation")
        
        print_section("DEMO TECHNICAL DETAILS")
        print("ğŸ”§ This demo showcases DACP's capabilities for:")
        print("   â€¢ Multi-agent workflow orchestration")
        print("   â€¢ Agent-to-agent data flow management") 
        print("   â€¢ Real-time security analysis pipelines")
        print("   â€¢ Structured JSON communication between agents")
        print("   â€¢ Behavioral contract enforcement across agents")
        
        print("\nğŸ¯ Real Implementation Requirements:")
        print("   â€¢ OAS-generated threat-analyzer and risk-assessor agents")
        print("   â€¢ Claude or OpenAI API keys configured")
        print("   â€¢ DACP workflow.yaml configuration file")
        print("   â€¢ Behavioral contracts for security analysis validation")
        
    else:
        # This would be the real implementation if agents were present
        print("ğŸš€ Loading OAS-generated security agents...")
        
        # Load the actual agents (when available)
        ThreatAnalyzerAgent = load_agent_from_file(threat_analyzer_path, "ThreatAnalyzerAgent")
        RiskAssessorAgent = load_agent_from_file(risk_assessor_path, "RiskAssessorAgent")
        
        # Create agent instances
        threat_analyzer = ThreatAnalyzerAgent(agent_id="threat-analyzer", orchestrator=orchestrator)
        risk_assessor = RiskAssessorAgent(agent_id="risk-assessor", orchestrator=orchestrator)
        
        # Run the actual workflow (implementation would be similar to simulation above)
        print("âœ… Real agents loaded - executing live workflow...")
    
    print_section("DEMONSTRATION COMPLETED",
                  "âœ… DACP security workflow demonstration finished!")
    print("\nğŸ“– For more DACP examples, see: examples/")
    print("ğŸ”— Learn more about Open Agent Stack: https://openagentstack.ai")


if __name__ == "__main__":
    main()